# 操作系统

## 操作系统启动

bootset.s：将操作系统从磁盘上读进来

setup.s：获得了一些参数启动了保护模式

head.s：初始化了一些GDT表，初始化了一些页表

main.c：main的工作就是xx_init：内存、中断、设备、时钟、CPU等内容的初始化。一堆mem_init、trap_init、blk_dev_init、chr_dev_init、tty_init、time_init、sched_init初始化内存，初始化，获得硬件的参数完成对硬件的初始化，形成关键的数据结构，将来完成对操作系统的管理

~~~C
//init/main.c
void main(void)
{
	mem_init();
	trap_init();
	blk_dev_init();
	chr_dev_init();
	tty_init();
	time_init();
	sched_init();
	buffer_init();
	hd_init();
	floppy_init();
	sti();
	move_to_user_mode();
	if (!fork()){init();}
}
~~~

做了两件事：把操作系统读入内存；初始化

操作系统读入内存才能取指执行，才能完成功能

全局描述表（Global Descriptor Table，GDT）：

中断描述表（Interrupt Descriptor Table，IDT）

## 操作系统接口

操作系统接口：接口表现为函数调用，又由系统提供，所以称为系统调用。

系统调用

POSIX（Portable Operating System Interface of Unix）（IEEE制定的一个标准）

|   分类   |   posiX定义    |         描述         |
| :------: | :------------: | :------------------: |
| 任务管理 |      fork      |     创建一个进程     |
|          |     excel      |  运行一个可执行程序  |
|          | pthread_create |     创建一个线程     |
| 文件系统 |      open      |  打开一个文件或目录  |
|          |     EACCES     | 返回值，表示没有权限 |
|          | mode_t st_mode | 文件头结构：文件属性 |

## 系统调用的实现（System Call）

区分内核态和用户态，不能随意访问内存 

硬件检查DPL（目标特权级）≥CPL（当前特权级）才可以访问

0是内核态，3是用户态

当前程序执行在什么态？CS:IP是当前指令，所以用CS最低两位来表示







进程是资源调度的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序。
线程是程序执行的基本单位，是轻量级的进程，每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。协程是用户态的轻量级线程，线程内部调度的基本单位

###### 线程与进程的比较

1. 线程启动速度快，轻量级
2. 线程的系统开销小
3. 线程使用有一定难度，需要处理数据一致性问题
4. 同一线程共享的有堆、全局变量、静态变量、指针、引用、文件等，而独自占有栈

###### 一个进程可以创建的线程数由可用虚拟空间和线程的栈大小决定

一个进程可用虚拟空间是2G，默认情况下线程的栈大小是1MB，所以理论最多可以创建2048个线程，再多就需要修改编译器的设置了。

太多的线程给程序的坏处：过多的线程导致大量的时间浪费在线程切换上，给程序运行带来负收益

###### 中断和异常区别

中断是指CPU执行指令以外的事件引起，如IO完成中断，表示设备输入输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。
异常是由CPU执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等

###### 进程线程模型

1. 线程创建和结束

   - 创建线程：int pthread_create(pthread_t *pthread, const pthread_attr_t *attr, void (start_routine)(void *), void *agr);

     创建一个线程，pthread和start_routine分别用于标识线程和执行体入口

   - 获得线程ID：pthread_t pthread_self();

   - 等待线程结束：int pthread_join (pthread_t tid, void *\* retval);

     主线程调用，等待子线程退出，并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞

   - 结束线程：pthread_exit(void *retval);

   - 分离线程：int pthread_detach(pthread_t tid);

     主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中，pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时，自己立即回收资源

2. 线程属性修改

   - 线程属性对象类型为pthread_attr_t定义如下

     ```c++
     typedef struct {
         int etachstate;	//线程分离的状态
         int schedpolicy;	//线程调度策略
         struct sched_param schedparam;	//线程的调度参数
         int inheritsched;	//线程的继承性
         int scope;	//线程的作用域
         //以下为线程栈的设置
         size_t guardisze;	//线程栈末尾警戒缓冲大小
         int stackaddr_set;	//线程的栈设置
         void *stackaddr;	//线程栈的位置
         size_t stakcsize;	//线程栈大小
     }ptrhead_attr_t;
     ```

   - 相关接口：pthread_attr_get()和pthread_attr_set()系统调用函数来设置和获取

多进程，进程是资源分配的基本单位。进程由代码段、堆栈段、数据段组成。代码段是静态的二进制代码，多个程序可以共享。父进程创建子进程之后，父、子进程除了pid外，所有的部分几乎一样

父、子进程共享全部数据，并不是说他们就是对同一块数据进行操作，子进程在读写数据时，会通过写时复制机制将公共数据重新拷贝一份，之后在拷贝出的数据上进行操作。如果子进程想要运行自己的代码段，还可以通过调用execv()函数重新加载新的代码段，之后就和父进程独立开了。

在shell中执行程序就是通过shell进程先fork()出一个子进程在通过execv()重新加载新的代码段的过程

1. 进程的创建与结束

   - 进程的两种创建方式，一种是操作系统创建的，一种是父进程创建的。

   - 计算机启动到终端执行程序的过程为：0号进程 -> 1号内核进程 -> 1号用户进程(init进程) -> getty进程 -> shell进程->命令行执行进程。

   - 创建进程：pid_t fork(void);

     出错返回-1；父进程中返回pid>0，子进程中pid=0

   - 结束进程：void exit(int status);

     status是退出状态，保存在全句柄中，通常0表示正常退出

   - 获得PID：pid_t getpid(void);

     返回调用者的pid

   - 获得父进程PID：pid_t getppid(void);

     返回父进程pid

   - 其他

     - 正常退出方式：exit()、_exit()、return（在main中）
     - exit()和_exit()区别：exit()是对\_exit()的封装，都会终止进程并做相关收尾工作，最主要的区别就是\_exit()函数关闭全部描述符和清理函数后不会刷新流，但是exit()函数会在调用\_exit()函数前刷新数据流
     - return和exit()区别：exit()是函数，但有参数，执行完之后控制权交给系统，return若是在调用函数中，执行完之后控制权交给调用进程，若是在main函数中控股职权交给系统
     - 异常退出方式：abort()，终止信号

2. Linux进程控制

   - 进程地址空间

     虚拟存储器为每个进程提供了独占系统地址空间的假象

     有一些"敏感"的地址需要注意下，对于32位进程来说，代码段从0x08048000开始。从0xC0000000开始 到0xFFFFFFFF是内核地址空间，通常情况下代码运行在用户态（使用0x00000000 ~ 0xC00000000的 用户地址空间），当发生系统调用、进程切换等操作时CPU控制寄存器设置模式位，进入内和模式， 在该状态（超级用户模式）下进程可以访问全部存储器位置和执行全部指令。 

     也就说32位进程的地址空间都是4G，但用户态下只能访问低3G的地址空间，若要访问3G ~ 4G的地址 空间则只有进入内核态才行。

   - 进程控制块

     进程的调度实际上就是内核选择相应的进程控制块，被选择的进程控制块中包含了一个进程基本的信息

   - 上下文切换

     内核管理所有进程控制块，而进程控制块记录了进程全部状态信息，每一次进程调度就是一次上下文切换，所谓的上下文本质上就是当前运行状态，主要包括通用寄存区、浮点寄存器、状态寄存器、程序计数器、用户栈和内核数据结构（页表、进程表、文件表）等

     进程执行时刻，内核可以决定抢占当前进程并开始新的进程，这个过程由内核调度器完成，当调度器 选择了某个进程时称为该进程被调度，该过程通过上下文切换来改变当前状态。

      一次完整的上下文切换通常是进程原先运行于用户态，之后因系统调用或时间片到切换到内核态执行 内核指令，完成上下文切换后回到用户态，此时已经切换到进程B。

###### 进程调度算法

1. 先来先服务（first come first server，FCFS）

   非抢占式调度算法，按请求的顺序进行调度

   有利于长作业，不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，导致短作业等待时间过长

2. 短作业优先（shortest job first，SJF）

   非抢占式调度算法，按运行时间最短顺序进行调度

   长作业有可能会饿死，处于一直等待短作业执行完毕的状态，因为如果一直有短作业到来，那么长作业永远得不到调度

3. 最短剩余时间优先（shortest remaining time next，SRTN）

   短作业优先的抢占版本，按剩余时间的顺序进行调度，当一个新的作业到达时，其整个运行时间与当前进程的剩余时间做比较

   如果新的进程需要的时间更少，则挂起当前进程，运行新的进程，否则新的进程等待。

4. 时间片轮转

   所有就绪进程按先来先服务原则排成一个队列，每次调度时，把CPU时间分给首进程，该进程可以执行一个时间片，当时间片用完，由计时器发出时钟中断，调度程序便停止该进程的执行，并把它送往就绪队列的末尾，同时把CPU时间分配给队首的进程

   时间片轮转算法的效率和时间片的大小有很大关系：

   - 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间
   - 而如果时间片过长，那么时效性就不能得到保证

5. 优先级调度

   为每个进程分配一个优先级，按优先级调度。

   为了防止低优先级的进程得不到调度，可以随着时间的推移增加等待进程的优先级

6. 多级反馈队列

   设置多个队列，每个队列时间片大小都不同，如1，2，4，8等，进程在第一个队列执行完就会被移到下一个队列

   每个队列优先权不同，最上面的优先权最高，因此只有上一个队列没有进程在排队，才能调度当前队列上的进程

   多级反馈队列可以看做是时间片轮转调度算法和优先级调度算法的结合

###### linux下进程间通信方式

- 管道： 
  - 无名管道（内存文件）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲 缘关系的进程之间使用。进程的亲缘关系通常是指父子进程关系。 
  - 有名管道（FIFO文件，借助文件系统）：有名管道也是半双工的通信方式，但是允许在没有亲缘 关系的进程之间使用，管道是先进先出的通信方式。 
- 共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多 个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设 计的。它往往与信号量，配合使用来实现进程间的同步和通信。 
- 消息队列：消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号 传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 
- 套接字：适用于不同机器间进程通信，在本地也可作为两个进程通信的方式。 
- 信号：用于通知接收进程某个事件已经发生，比如按下ctrl + C就是信号。 
- 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实 现进程、线程的对临界区的同步及互斥访问。

###### Linux下同步机制

POSIX信号量：可用于进程同步，也可用于线程同步
POSIX互斥锁+条件变量：只能用于线程同步

###### Linux具有块表，地址转换过程

1. CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。 
2. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因 此，若快表命中，则访问某个逻辑地址仅需一次访存即可。 
3. 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块 号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因 此,若快表未命中，则访问某个逻辑地址需要两次访存(注意:在找到页表项后，应同时将其存入快表, 以便后面可能的再次访问。但若快表已满，则必须按照-定的算法对旧的页表项进行替换)

###### 内存交换和覆盖区别

交换主要是不同进程（或作业）之间进行，覆盖用于同一程序或进程中

###### 动态分区分配算法有哪几种

1. 首次适应算法
   - 算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区
   - 实现：空闲分区以**地址递增的次序排列**，每次分配内存时，顺序查找空闲分区链（或空闲分表），找到大小能满足要求的第一个空闲分区
2. 最佳适应算法
   - 算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片空闲区，即优先使用更小的空闲区
   - 实现：空闲分区按**容量依次递增次序链接**，每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区
   - 缺点：每次使用最小的分区进行分配，越来越多的难以利用的小内存快会被遗留下来，因此这种防范会产生很多外部碎片
3. 最坏（最大）适应算法
   - 算法思想：为了解决最佳适应算法的问题——即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后的剩余空闲区就不会太小，更方便使用
   - 实现：空闲分区按**容量递减次序链接**，每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区
   - 缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，可利用，但是这种方式会导致较大的连续空闲区被迅速用完，如果之后有“大进程”到达，就没有内存可以用了
4. 临近适应算法
   - 算法思想：首次适应算法每次都从联投开始查找，这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销，如果每次都从上次查找结束的位置开始检索，就能解决上述问题
   - 实现：空闲分区以地址递增的顺序排列。每次分配内存时从上次查找结束的位置开始查找空闲分区链，找到大小能满足要求的第一个空闲分区
   - 首次适应算法每次都从链头开始查找，每次都需要检索低地址的小分区因此也决定了当低地址部分有更小的分区可以满足需求时，会更有可能使用到低地址部分的小分区，也会更有坑你把高地址部分的大分区保留下来（最佳适应算法的优点）
   - 临近适应算法的规则可能导致无论低地址、高地址部分的空闲分区都有相同概率被使用，也就导致了高地址部分的大分区更可能被使用划分为小分区，最后导致无大分区可用（最大适应算法的缺点）
   - 综合来看，四种算法中，首次适应算法的效果最佳
5. 总结
   - 首次适应算法不仅简单，通常也是最好最快的，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。临近算法试图解决这个问题，但实际上，它常常导致在内存的末尾分配空间分裂成小的碎片。它通常比首次适应算法结果要差
   - 最佳导致大量碎片，最坏导致没有大的空间

###### 虚拟技术

- 时（时间）分复用
  - 多进程与多线程：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换
- 空（空间）分复用
  - 虚拟内存使用了空分复用技术，将物理内存抽象为地址空间，每个进程都有各自的地址空间，地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中

###### 进程状态切换

- 就绪状态：等待被调度
- 运行状态
- 阻塞状态

注意：

- 只有就绪状态和运行状态可以相互转换，其他都是单向转换，就绪状态的进程通过调度算法从而获得CPU时间，转为运行状态；而运行状态的进程，在分配各它的CPU时间片用完之后就会转为就绪状态，等待下一次调度
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括CPU时间，缺少CPU时间会从运行态转换为就绪态

###### 静态链接和动态链接

1. 静态链接： 函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库 中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。 
   - 优点：不需要额外的文件，一个文件就包括所有内容，没有加载文件的额外消耗
   - 空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个 目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本； 
   - 更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。 
   - 运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西， 在执行的时候运行速度快。 
2. 动态链接： 动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形 成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。 
   - 共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副 本，而是这多个程序在执行时共享同一份副本； 
   - 更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运 行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。
   -  性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损 失。

###### 逻辑地址转换为物理地址的过程

###### 进程同步的四种方法

1. 临界区

   - 对临界资源进行访问的那段代码称为临界区
   - 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查

2. 同步与互斥

   - 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系
   - 互斥：多个进程在同一时刻只有一个能进入临界区

3. 信号量

   - 信号量是一个整型变脸，可以对其执行down和up操作，也就是常见的P和V操作
     - down：如果信号量大于0，执行-1操作；如果信号量等于0，进行睡眠，等待信号量大于0；
     - up：对信号量执行+1操作，唤醒睡眠的进程让其完成down操作
   - down和up操作需要被设计成原语，不可分割，通常的做法是在执行这些操的时候屏蔽中断
   - 如果信号量的取值只能为0或者1，那么就成为了互斥量（Mutex），0表示临界区已经加锁，1表示临界区解锁

4. 管程：在一个时刻只能有一个进程使用管程，进程在无法继续执行的时候不能一直占用管程，否则其他进程永远不能使用管程。

   管程引入**条件变量**以及相关操作wait()和signal()来实现同步操作，对条件变量执行wait()操作会导致调用进程阻塞，把管程让出来给另一个进程持有，signal()操作用于唤醒被阻塞的进程

###### 操作系统在对内存进行管理的时候需要做些什么

1. 操作系统负责内存空间的分配与回收
2. 操作系统需要提供某种技术从逻辑上对内存空间进行扩充
3. 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换
4. 操作系统需要提供内存保护功能，保证各进程在各自存储空间内运行，互不干扰

###### 进程间通信方法、线程间通信方法

Linux线程通信方法：

- 信号：类似于进程间的信号处理
- 锁机制：互斥锁、读写锁和自旋锁
- 条件变量：使用通知的方式解锁，与互斥锁配合使用
- 信号量：包括无名线程信号量和命名线程信号量

###### 进程间通信方式

1. 管道 

   - 无名管道 
     - 无名管道特点： 
       - 无名管道是一种特殊的文件，这种文件只存在于内存中。 
       - 无名管道只能用于父子进程或兄弟进程之间，必须用于具有亲缘关系的进程间的通信。 
       - 无名管道只能由一端向另一端发送数据，是半双工方式，如果双方需要同时收发数据需要两个 管道。 
     - 相关接口： 
       - int pipe(int fd[2]); 
         - fd[2]：管道两端用fd[0]和fd[1]来描述，读的一端用fd[0]表示，写的一端用fd[1]表示。通信双 方的进程中写数据的一方需要把fd[0]先close掉，读的一方需要先把fd[1]给close掉。 
    - 有名管道： 
       - 有名管道特点： 
          - 有名管道是FIFO文件，存在于文件系统中，可以通过文件路径名来指出。 
          - 有名管道可以在不具有亲缘关系的进程间进行通信。 
       - 相关接口： 
          - int mkfifo(const char *pathname, mode_t mode); 
             - pathname：即将创建的FIFO文件路径，如果文件存在需要先删除。 
             - mode：和open()中的参数相同。 
   
1. 消息队列 相比于 FIFO，消息队列具有以下优点： 
   - 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 
   - 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 
   - 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 
   
1. 共享内存 进程可以将同一段共享内存连接到它们自己的地址空间，所有进程都可以访问共享内存中的地址，如果 某个进程向共享内存内写入数据，所做的改动将立即影响到可以访问该共享内存的其他所有进程。 
   - 相关接口 
     - 创建共享内存：int shmget(key_t key, int size, int flag); 成功时返回一个和key相关的共享内存标识符，失败范湖范围-1。 
       - key：为共享内存段命名，多个共享同一片内存的进程使用同一个key。 
       - size：共享内存容量。 
       - flag：权限标志位，和open的mode参数一样。 
     
   - 连接到共享内存地址空间：void *shmat(int shmid, void *addr, int flag); 
   
     返回值即共享内存实际地址。 
   
     - shmid：shmget()返回的标识。 
     - addr：决定以什么方式连接地址。 
     - flag：访问模式。 
     
   - 从共享内存分离：int shmdt(const void *shmaddr); 调用成功返回0，失败返回-1。 
   
     - shmaddr：是shmat()返回的地址指针。 
     
   - 其他补充 共享内存的方式像极了多线程中线程对全局变量的访问，大家都对等地有权去修改这块内存的值，这 就导致在多进程并发下，最终结果是不可预期的。所以对这块临界区的访问需要通过信号量来进行进 程同步。 
   
     但共享内存的优势也很明显，首先可以通过共享内存进行通信的进程不需要像无名管道一样需要通信 的进程间有亲缘关系。其次内存共享的速度也比较快，不存在读取文件、消息传递等过程，只需要到 相应映射到的内存地址直接读写数据即可。 
   
1. 信号量 在提到共享内存方式时也提到，进程共享内存和多线程共享全局变量非常相似。所以在使用内存共享的 方式是也需要通过信号量来完成进程间同步。**多线程同步的信号量是POSIX信号量，而在进程里使用 SYSTEM V信号量。** 

   - 相关接口 
     - 创建信号量：int semget(key_t key, int nsems, int semflag); 创建成功返回信号量标识符，失败返回-1。 
       - key：进程pid。 
       - nsems：创建信号量的个数。 
       - semflag：指定信号量读写权限。 
       
     - 改变信号量值：int semop(int semid, struct sembuf *sops, unsigned nsops); 
     
       我们所需要做的主要工作就是串讲sembuf变量并设置其值，然后调用semop，把设置好的sembuf变 量传递进去。 struct sembuf结构体定义如下：
     
       ```c++
       struct sembuf {
           short sem_num;
           short sem_op;
           short sem_flg;
       };
       ```
     
       成功返回信号量标识符，失败返回-1。 
     
     - semid：信号量集标识符，由semget()函数返回。 
     
     - sops：指向struct sembuf结构的指针，先设置好sembuf值再通过指针传递。 
     
     - nsops：进行操作信号量的个数，即sops结构变量的个数，需大于或等于1。最常见设置此值等于 1，只完成对一个信号量的操作。 
     
   - 直接控制信号量信息：int semctl(int semid, int semnum, int cmd, union semun arg); 

     - semid：信号量集标识符。 
     - semnum：信号量集数组上的下标，表示某一个信号量。 
     - arg：union semun类型。 

1. 辅助命令 

   ipcs命令用于报告共享内存、信号量和消息队列信息。 

   - ipcs -a：列出共享内存、信号量和消息队列信息。 
   - ipcs -l：列出系统限额。 
   - ipcs -u：列出当前使用情况。 

1. 套接字 与其它通信机制不同的是，它可用于不同机器间的进程通信。

###### 虚拟内存的目的是什么

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存
为了更好的管理内存，操作系统将内存抽象成地址空间，每个程序拥有自己的地址空间，这个地址空间分割成多个块，每个块称为一页
这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令
虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能

###### 哲学家进餐

必须设置两个条件

- 必须同时拿起左右两根筷子
- 只有在两个邻居都没有进餐的情况下才允许进餐

###### 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生

###### 几种典型的锁

- 读写锁

  - 多个读者可以同时记性读
  - 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）
  - 写者优先于读者（一旦有写者，后续读者必须等待，唤醒时优先考虑写者）

- 互斥锁

  一次只能一个线程拥有互斥锁，其他线程只有等待

  互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或进程，需要把锁交给操作系统管理

  所以互斥锁在加锁操作时涉及了上下文的切换，互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能实现是先自旋一段时间，当自旋的时间超过阈值之后，再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）效果可能不亚于使用自旋锁

- 条件变量 

  互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个 线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足 时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变 量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。

  总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。 

- 自旋锁 

  如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。 如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短 的场景，这个时候效率比较高。
  
  

###### 几种线程锁

- 互斥锁
  - 互斥锁属于sleep-waiting类型的锁。例如在一个双核的机器上有两个线程A和B，它们分别运行在core 0和core 1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被 线程B所持有，那么线程A就会被阻塞，此时会通过上下文切换将线程A置于等待队列中，此时core 0 就可以运行其他的任务（如线程C）。
- 条件变量(cond)
- 自旋锁(spin) 
  - 自旋锁属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，如果自旋锁已 经被线程B所持有，那么线程A就会一直在core 0上进行忙等待并不停的进行锁请求，检查该自旋锁是 否已经被线程B释放，直到得到这个锁为止。因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远 高于互斥锁。 
  - 虽然它的效率比互斥锁高，但是它也有些不足之处： 
    - 自旋锁一直占用CPU，在未获得锁的情况下，一直进行自旋，所以占用着CPU，如果不能在很短的 时间内获得锁，无疑会使CPU效率降低。 
    - 在用自旋锁时有可能造成死锁，当递归调用时有可能造成死锁。 
  - 自旋锁只有在内核可抢占式或SMP的情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的 操作为空操作。自旋锁适用于锁使用者保持锁时间比较短的情况下。

###### 回收线程的方法

- 等待线程结束： int pthread_join(pthread_t tid, void **retval);

  主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞

  - tid：创建线程时通过指针得到tid值
  - retval：指向返回值的指针

- 结束线程：pthread_exit(void **retval);

  子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得

- 分离线程：int pthread_detach(pthread_t tid);

  主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程，pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时，自己立即回收资源

###### 内存的覆盖是什么？有什么特点？ 

由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间 分成为一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先 将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆 盖区中原有的段。 

覆盖技术的特点：是打破了必须将一个进程的全部信息装入内存后才能运行的限制，但当同时运行程序 的代码量大于主存时仍不能运行，再而，大家要注意到，内存中能够更新的地方只有覆盖区的段，不在 覆盖区的段会常驻内存。

###### 内存交换是什么？有什么特点？ 

交换(对换)技术的设计思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已 具备运行条件的进程换入内存(进程在内存与磁盘间动态调度) 

换入：把准备好竞争CPU运行的程序从辅存移到内存。
换出：把处于等待状态（或CPU调度原则下被剥夺运行权力）的程序从内存移到辅存，把内存空间腾出 来。

###### 终端退出，终端运行的进程会怎样 

终端在退出时会发送SIGHUP给对应的bash进程，bash进程收到这个信号后首先将它发给session下面的进 程，如果程序没有对SIGHUP信号做特殊处理，那么进程就会随着终端关闭而退出

###### 如何让进程后台运行 

1. 命令后面加上&即可，实际上，这样是将命令放入到一个作业队列中了 
2. ctrl + z 挂起进程，使用jobs查看序号，在使用bg %序号后台运行进程 
3. nohup + &，将标准输出和标准错误缺省会被重定向到 nohup.out 文件中，忽略所有挂断 （SIGHUP）信号 
4. 运行指令前面 + setsid，使其父进程编程init进程，不受HUP信号的影响 
5. 将 命令+ &放在()括号中，也可以是进程不受HUP信号的影响

###### 什么是快表，你知道多少关于快表的知识？ 

快表，又称联想寄存器(TLB) ，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的 若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。

- 基本地址变换机构

  地址变换过程：

  1. 算页号、页内偏移量
  2. 检查页号合法性
  3. 查页表、找到页面存放的内存块号
  4. 根据内存块号与页内偏移量得到物理地址
  5. 访问目标内存单元

  访问一个逻辑地址的访存次数：两次访存

- 具有快表的地址变换机构

  地址变换过程：

  1. 算页号、页内偏移量
  2. 检查页号合法性
  3. 查快表，若命中，即可知道页面存放的内存块号，可直接进行访存
  4. 若未命中则进行，则查页表，找到页面存放的内存块号，并且将页表项复制到快表中
  5. 根据内存块号与页内偏移量得到物理地址
  6. 访问目标内存单元

  快表命中，只需一次访存，快表未命中，需要两次访存

###### 守护进程、僵尸进程和孤儿进程

- 守护进程 

  指后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性的执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等

  创建守护进程要点：

  1. 让程序在后台执行，方法是调用fork()产生一个子进程，然后使父进程退出
  2. 调用setsid()创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid()使进程称为一个会话组长。setsid()调用成功后，进程称为ixnde会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。
  3. 禁止进程重新打开控制终端。经过以上步骤，进程已经称为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现，再一次通过fork()创建新的子进程，使用fork的进程退出
  4. 关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符
  5. 将当前目录更改为根目录
  6. 子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为了防止这一点，使用unmsk(0)将屏蔽字清零
  7. 处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程。从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样子进程结束时，不会产生僵尸进程

- 孤儿进程

  如果父进程先退出，子进程还没退出，那么子进程的父进程将变为init进程。（注：任何一个进程都必须有父进程）。

  一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。

- 僵尸进程

  如果子进程先退出，父进程还没退出，那么子进程必须等待到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。

  设置僵尸进程的目的是维护子进程的信息，以便父进程在以后的某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用wait或waitpid时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。继承这些子进程的  init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）

###### 如何避免僵尸进程

- 通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂 起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN);表示父进程忽略SIGCHLD信号，该 信号是子进程退出的时候向父进程发送的。
- 父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回
- 如果父进程很忙可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出
- 通过两次调用fork()，父进程首先调用fork()创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于子子进程，其父进程已经退出，所以子子进程称为一个孤儿进程，孤儿进程由init进程接管，子子进程结束后，init会等待回收

第一种方法忽略SIGCHLD信号，常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可以让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源

###### 局部性原理

- 时间局部性原理：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不就之后该数据很可能再次被访问（因为程序中存在大量的循环）
  - 
- 空间局部性原理：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的）
  - 外存→内存→高速缓存→寄存器，从左至右容量越小，速度越快，价格越高。
  - 快表规则就是将近期常访问的页表项副本放到更高速的联想寄存器中
  - 高速缓冲技术：将近期会频繁访问到的数据放到更高速的存储器中，暂时用不到的数据放到更低速寄存器中

###### 父进程、子进程、进程组、作业和会话

- **父进程**

  已创建一个或多个进程的进程

- **子进程**

  由fork创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别 是子进程的返回值是0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程id返回给父进程的 理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程 id。对子进程来说，之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid；也可以调 用getppid()来获取父进程的id。(进程id 0总是由交换进程使用，所以一个子进程的进程id不可能为0 )。 

  fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来， 他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容 是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数 器pc值相同，也就是说，子进程是从fork返回处开始执行的），但有一点不同，如果fork成功，子进程中 fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。

  子进程从父进程继承到的有：

  - 进程的资格（真实(reral)/有效(effective)/已保存(saved)、用户号(UIDs)、组号(GIDs)）
  - 环境
  - 堆栈
  - 内存
  - 进程组号

  独有：

  - 进程号
  - 不同的父进程号（子进程的父进程号和父进程的父进程号不同，父进程号由getppid函数得到）
  - 资源使用（resource utilizations）设定为0

- 进程组

  就是多个进程的集合，其中肯定有一个组长，其进程PID等于进程组的PGID。只要在某个进程组中一个进程存在，该进程组就存在，这与其组长进程是否终止无关

- 作业

  shell分前后台来控制的不是进程而是作业（job）或者进程组

  一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，shell可以运行一个前台作业和任意多个后台作业，这称为作业控制

  **为什么只能运行一个前台作业**

  当前台新起了一个作业，shell就被提到了后台，因此shell就没有办法再继续接受指令并且解析运行了。但是如果前台进程退出了，shell就会又被提到前台来，就可以继续接受命令并且解析运行

  作业与进程组的区别：如果作业中的某个进程由创建了子进程，则该子进程是不属于该作业的。一旦作业运行结束，shell就把自己提到了前台（自子进程还在，但是子进程不属于作业），如果原来的前台进程还存在（这个子进程还没有终止），他将自动变为后台进程组

- 会话

  会话（session）是一个或多个进程组的集合，一个会话可以有一个控制终端。在Xshel中打开一个窗口就是新建一个会话

###### 进程终止的几种方式

1. main函数自然返回 return
2. 调用exit函数
3. 调用_exit函数
4. 调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程
5. 接受能导致进程终止的信号：ctrl+c(^C)、SIGINT（SIGINT中断进程）

###### 中断和异常

- 中断是由硬件设备产生的，从物理上就是电信号，通过中断控制器发送给CPU，接着CPU判断收到的中断来自哪个硬件设备（这定义在内核中）。最后，由CPU发送给内核，内核处理中断
- 异常是由CPU产生的，同时，它会发送给内核，要求内核处理这些异常
- 相同点：
  - 最后都是由CPU发送给内核，由内核去处理
  - 处理程序的流程设计上是相似的
- 不同点：
  - 产生源不同，异常是由CPU产生的，中断是由硬件设备产生的
  - 内核需要根据是异常还是中断调用不同的处理程序
  - 中断不是时钟同步的，这意味着中断可能随时到来；异常由于是CPU产生的，所以是时钟同步的
  - 当处理中断时，处于中断上下文中；处理异常时，处于进程上下文中

###### 内存分布情况

从低到高分别为：

1. 程序文件段，包括二进制可执行代码
2. 已初始化数据段，包括静态常量
3. 未初始化数据段，包括未初始化的静态变量
4. 堆段，包括动态分配的内存，从低地址开始向上增长
5. 文件映射段，包括动态库，共享内存等，从低地址开始向上增长
6. 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是8MB，系统也提供了参数以便自定义大小

###### C/C++程序占用的内存分为五部分

1. 栈区：地址向下增长，由编译器自动分配释放，存放函数的参数值，局部变量的值等
2. 堆区：地址向上增长，一般由程序员分配释放，若程序员不释放，程序结束后由操作系统回收。
3. 全局区（静态区）：全局变量和静态变量的存储是放在一起的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束后由系统释放
4. 常量区
5. 程序代码区：存放程序的二进制代码

###### 程序从堆中动态分配内存时，虚拟内存上是怎么操作的

页表：是一个存放在物理内存中的数据结构，记录了虚拟页与物理页的映射关系

在进行动态内存分配时，例如malloc()函数或者new关键字，操作系统会在磁盘中创建或者申请一段虚拟内存空间，并更新到页表（分配一个页表条目(PTE)，使该PTE指向硬盘上这个新创建的虚拟页），通过PTE建立虚拟页和物理页的映射关系

###### 常见的几种磁盘调度算法

影响磁盘块读写时间的因素：

- 旋转时间（主轴旋转盘面，使得磁头移动到适当地扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当地磁道上）
- 实际的数据传输时间

其中寻道时间最长，因此磁盘调度的主要目的是使磁盘的平均寻道时间最短

1. 先来先服务

   按照磁盘请求的顺序进行调度

   优点是公平和简单，缺点是未对寻道做任何优化，使平均寻道时间可能较长

2. 最短寻道时间优先

   优先调度与当前磁头所在磁道距离最近的磁道

   虽然平均时间比较低，但是不够公平，如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说两端的磁道请求更容易出现饥饿现象

3. 电梯扫描算法

   电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

   电梯算法（扫描算法）和电梯运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

   因为考虑了移动方向，因此所有的磁盘请求都会满足

###### 交换空间与虚拟内存的关系

- 交换空间 

  Linux 中的交换空间（Swap space）在物理内存（RAM）被充满时被使用。如果系统需要更多的内存资 源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内 存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进 入物理内存要慢。 

  交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。

   交换空间的总大小应该相当于你的计算机内存的两倍和 32 MB这两个值中较大的一个，但是它不能超过 2048MB（2 GB）。 

- 虚拟内存 

  虚拟内存是文件数据交叉链接的活动文件。是WINDOWS目录下的一个"pagefile.sys"文件，这个文件 会不断地扩大和自动缩小。 
  
  就速度方面而言,CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是虚拟内存使用的是硬盘的 空间，为什么我们要使用速度最慢的硬盘来做 为虚拟内存呢？因为电脑中所有运行的程序都需要经过内 存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空 间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充 当内存使用

###### 抖动

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够）
为进程分配的物理块太少，会导致进程发生抖动现象，为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率
进程工作集

###### 从堆和栈上建立对象哪个快（考虑堆和栈的分配效率比较）

- 分配和释放，堆在分配和释放时都要调用函数（malloc，free），比如分配时会到堆空间去寻找足够到小的空间（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，函数做了很多额外的工作。栈却不需要
- 访问时间，访问堆的一个具体单元，需要两次访问内存，第一次取得指针，第二次才是真正的数据，而栈只需访问一次。另外堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去

###### 常见的内存分配方式有哪些

1. 从静态存储区域分配，内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在，如全局变量、static变量
2. 在栈上创建。执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限
3. 从堆上分配内存，程序在运行的时候用new或malloc申请内存，程序员负责何时delete或free释放内存

###### 常见的内存分配错误

1. 内存分配未成功，却使用了它

   检查指针是否为NULL

2. 内存分配成功，但是尚未初始化就使用了

3. 内存分配成功并且已经初始化，但是操作越过内存的边界

4. 忘记释放内存，导致内存泄漏

5. 释放了内存，却继续使用

   - free或delete释放内存后，要将指针设置为NULL，否则会产生野指针
   - 函数的return语句不要返回指向“栈内存”的指针或者“引用”，因为该内存在函数体结束后就会自动销毁

###### 内存交换中，被换出的内存保存在那里

保存在磁盘中，也就外存。具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式；对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式。总之，对换区的I/O速度比文件区更快

###### 在发生内存交换时，有些进程是被优先考虑的

可优先换出阻塞进程；可换出优先级低的进程；为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间（注意：PCB会常驻内存，不会被换出外存）

###### Unicode和UTF-8

Unicode两个字节表示一个字符
UTF-8将Unicode字符按数字大小编码为1-6个字节，英文字母被编码成一个字节，常用汉字被编码成三个字节

1. 计算机内存中，同一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码
2. 用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件

###### 原子操作是如何实现的

**处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作**。首先处理器会保证基本内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。

处理器提供总线锁定和缓存锁定两个机制保证复杂内存操作的原子性

1. 使用总线锁保证原子性

   如果多个处理器同时对共享变量进行读改写操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。

   如i++，原因是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么要想保证读改写共享变量的操作是原子的，就必须保证CPU读改写操作共享变量的时候，别的COU不能操作缓存了该共享变量内存地址的缓存

   处理器使用总线锁就是解决这个问题。**总线锁就是使用处理器提供的一LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，该处理器就会独占共享内存**

2. 使用缓存锁保证原子性

   第二个机制是通过缓存锁定保证原子性。在同一时刻，只需要保证对某个内存地址的操作是原子性即可，但**总线锁定把CPU和内存之间的通信锁住了**，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化

   频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁。

   “缓存锁定”是指内存区域如果被缓存在处理器的缓存中，并且在lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声明LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性。因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i使用了缓存锁定，那么CPU2就不能同时缓存i的缓存行**

   有两种情况下处理器不会使用缓存锁定：

   1. 当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时，则处理器会调用总线锁定
   2. 有些处理器不支持缓存锁定，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定

###### 内存交换注意的关键点

1. 交换需要备份存储，通常是快速磁盘，必须足够大，并且提供对这些内存映像的直接访问
2. 为了有效使用CPU，需要每个进程执行时间比交换时间长，映像交换时间的主要是转移时间，转移时间与所交换的空间内存成正比
3. 如果换出进程，比如确保该进程的内存空间成正比
4. 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快
5. 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停
6. 普通交换使用不多，但交换的策略的某些变种在许多系统中（如UNIX系统）仍然发挥作用

###### 系统并发和并行

并发是指宏观上一段时间内能运行多个程序，而并行则指同一时刻能运行多个指令

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统
操作系统通过引入进程和线程，使得程序能够并发运行

###### 页面置换算法

1. 最佳置换算法（OPT）

   每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，保证最低的缺页率

   最佳置换算法保证最低的缺页率，但实际上，只有进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列，因此，最佳置换算法无法实现

2. 先进先出算法（FIFO）

   每次选择淘汰的页面是最早进入内存的页面
   实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换粗页面时选择头页面，队列的最大长度取决于系统为进程分配了多少个内存块

   Belady异常：当为进程分配的物理块数增大时，缺页次数不减反增的异常现象

   只有FIFO算法会产生Belady异常，而LRU和OPT算法永远不会出现Belady异常。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此算法吸能差

   虽然FIFO性能差，因为较早调入的页往往是经常被访问的页，这些页在FIFO算法下被反复调入和调出，并且有Belady异常

3. 最近最久未使用置换算法（LRU）

   每次淘汰的页面是最近最久未使用的页面
   赋予每个页面对应的页表项中，用访问字段记录该页面上自上次被访问依赖所经历的时间t（该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大）。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面

   LRU性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类算法，理论上可以证明，堆栈类算法不可能出现Belady异常

4. 时钟置换算法（CLOCL）

   最佳置换算法OPT性能最好，但无法实现；先进先出算法时间简单，但算法性能差；最近最久未使用置换算法性能好，是最接近OPT算法吸能的，但是实现起来需要专门的硬件支持，算法开销大。
   所以设计了比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体，因为算法要循环扫描缓冲区像时钟一样转动，所以叫clock算法时钟

   时钟置换算法是一种性能和开销比较均衡的算法，又称CLOCK算法或最近未使用算法（NRU）

   实现方法：为每个页面设置一个访问位，再将内存中的页面通过链接指针链接成一个循环队列，当某页被访问时，其访问位置为1，当需要淘汰一个页面时，只需检查页的访问位，如果是0，就选择该页换出，如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第··轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择淘汰页面最多会经过两轮扫描）

5. 改进型CLOCK算法

   第一轮:从当前位置开始扫描到第一个(A =0, M = 0)的帧用于替换。表示该页面最近既未被访问，又 未被修改，是最佳淘汰页 

   第二轮:若第一轮扫描失败，则重新扫描，查找第一个(A =1, M = 0)的帧用于替换。本轮将所有扫描 过的帧访问位设为0。表示该页面最近未被访问，但已被修改，并不是很好的淘汰页。 

   第三轮:若第二轮扫描失败，则重新扫描，查找第一个(A =0, M = 1)的帧用于替换。本轮扫描不修改 任何标志位。表示该页面最近已被访问，但未被修改，该页有可能再被访问。 

   第四轮:若第三轮扫描失败，则重新扫描，查找第一个A =1, M = 1)的帧用于替换。表示该页最近已 被访问且被修改，该页可能再被访问。

   最多经过四轮扫描

   算法规则：将所有可能被置换的页面排成一个循环队列 

   第一轮:从当前位置开始扫描到第-一个(0, 0)的帧用于替换。本轮扫描不修改任何标志位。(第一优先级: 最近没访问，且没修改的页面) 

   第二轮:若第一轮扫描失败，则重新扫描，查找第一个(0, 1)的帧用于替换。本轮将所有扫描过的帧访问 位设为0 (第二优先级: 最近没访问，但修改过的页面) 

   第三轮:若第二轮扫描失败，则重新扫描，查找第一个(0, 0)的帧用于替换。本轮扫描不修改任何标志位 (第三优先级:最近访问过，但没修改的页面) 

   第四轮:若第三轮扫描失败，则重新扫描，查找第一个(0, 1)的帧用于替换。(第四优先级:最近访问过，且 修改过的页面) 

   由于第二轮已将所有帧的访问位设为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改 进型CLOCK置换算法选择一个淘汰页面最多会进行四轮扫描

###### 共享是什么

共享是指系统中的资源可以被多个并发进程共同使用

有两种共享方式：互斥共享和同时共享

互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问

###### 死锁

**死锁是指两个（或多个）线程相互等待对方数据的过程，死锁的产生会导致程序卡死，不解锁程序将永远无法进行下去**

1. **死锁产生原因**

   死锁产生的四个必要条件，缺一不可：

   1. **互斥条件**：线程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待
   2. **不剥夺条件**：线程在所获度的资源位释放前，不能被其他进程强行夺走，只能自己释放
   3. **请求和保持条件**：线程当前所拥有的的资源在进程请求其他新资源时，由该进程继续占有
   4. **循环等待条件**：存在一种线程资源循环等待链，链中每个线程已获得的资源同时被链中下一个线程所请求

2. 1

3. 死锁的解决方案

    破坏死锁产生的条件

4. 死锁必要条件

   - 互斥条件
   - 不剥夺条件
   - 请求和保持条件
   - 循环等待条件

5. 处理方法呢

   - 鸵鸟策略：假装没发生死锁

     因为解决死锁问题的代价很高，因此鸵鸟策略不采取任务措施的方案会获得更高的性能

     当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。Linux、Unix和Windows仅仅是忽略

   - 死锁检测与恢复

     不阻止死锁，而是当检测到死锁发生时，采取措施进行恢复

     每种类型一个资源的死锁检测：通过检测有向图是否存在环来实现。从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记过的节点，就表示有向图存在环，检测到死锁的发生

     死锁恢复：

     - 利用抢占恢复
     - 利用回滚恢复
     - 通过杀死进程恢复

   - 死锁预防

     在程序运行之前预防死锁

     1. 破坏互斥条件

        例如假设打印机技术允许若干个进程同时输出，唯一真正请求物理打印机进程的是打印机守护进程

     2. 破坏请求和保持条件

        规定所有进程在开始执行前请求所需要的全部资源

     3. 破坏不剥夺条件

        允许抢占资源

     4. 破坏循环等待条件

        给资源统一编号，进程只能按编号顺序来请求资源

   - 死锁避免

     银行家算法

###### 为什么分段式存储管理有外部碎片而无内部碎片？为什么固定分区分 配有内部碎片而不会有外部碎片？

分段式分配是按需分配，而固定式分配是固定分配的方式

###### 内部碎片与外部碎片

内碎片：分配给某些进程的内存区域中有些部分没用上，常见于固定分配方式 

内存总量相同，100M 

固定分配，将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M， 剩下的5M就是内部碎片； 

分段式分配，按需分配，一个程序需要45M，就给分片45MB，剩下的55M供其它程序使用，不存在内部碎片。 

外碎片：内存中某些空闲区因为比较小，而难以利用上，一般出现在内存动态分配方式中 

分段式分配：内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间 之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序 使用，只能从头开始分片，这样，就会存在10M+5M的外部碎片

###### 如何消除碎片文件

对于外部碎片，通过**紧凑技术**消除，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定 位寄存器地支持，且相对费时。紧凑地过程实际上类似于Windows系统中地磁盘整理程序，只不过后者 是对外存空间地紧凑 

解决外部内存碎片的问题就是内存交换。 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时 候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出 连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。 

回收内存时要尽可能地将相邻的空闲空间合并。

###### 多进程和多线程的区别是什么？换句话说，什么时候该用多线程，什 么时候该用多进程？

- 频繁修改：需要频繁创建和销毁的优先使用**多线程** 

- 计算量：需要大量计算的优先使用多线程 因为需要消耗大量CPU资源且切换频繁，所以**多线程**好一 点 

- 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同 步比较简单。 

- 多分布：可能要扩展到多机分布的用**多进程**，多核分布的**用多线程**。 

  但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

###### 服务器高并发的解决方案

- 应用数据与静态资源分离 

  将静态资源（图片，视频，js，css等）单独保存到专门的静态资源服务器中，在客户端访问的时候从 静态资源服务器中返回静态资源，从主服务器中返回应用数据。 

- 客户端缓存 

  因为效率最高，消耗资源最小的就是纯静态的html页面，所以可以把网站上的页面尽可能用静态的来 实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用ajax异步请 求获取动态数据。 

- 集群和分布式 （集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用）

###### 执行malloc申请内存，操作系统动作

从操作系统层面上看，malloc是通过两个系统调用来实现的： brk和mmap 

- brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小 

- mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内 存。 

通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内 存。 

进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址 的时候，通过缺页中断，让内核分配相应的物理内存，这样内存分配才算完成。

